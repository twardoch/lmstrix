
Research, then /plan into @PLAN.md and @TODO.md how to do the following TASK. Think about the plan, reflect, revise, refine the plan. 

TASK:

Into @_keep_this/adam/adamall.py write a tool that uses our lmstrix inference. 

Our goal is to write outputs into @_keep_this/adam/out in form of f"{safe_prompt_name}--{safe_model_id}.txt" where safe_model_id is the model ID made passed through https://pypi.org/project/pathvalidate/ `from pathvalidate import sanitize_filename; safe_model_id = sanitize_filename(model_id);`, and safe_prompt_name is similarly made from prompt_name

We load all models from our database, sorted by "smart" method (as used with "lmstrix list"). 

We plan that for each model we will run the prompts `think,aps`, `think,humanize`, `think,tldr`, `think,tts_optimize`, `translate`, and `tldr` from the prompt file @_keep_this/adam/adam.toml with the text @_keep_this/adam/fontlab8.md

We then upfront construct a list of paths into which we will write the outputs (f"_keep_this/adam/out/{safe_prompt_name}--{safe_model_id}.txt"). We check for the existence of each file corresponding to the path. If the file exists, we don't do anything. 

If the file does not exist, we check if the model that interests us is loaded. If not, we load the model with 50% input context size and prepare inference for 90% of its max context size. 

Then we inference the prompt with the model, and we write the output into the file. And we move to the next path ( that is model ID + prompt combo )

We do everything to ensure that we don't load/unload models UNNECESSARILY and that we don't inference UNNECESSARILY. 

We also perform the model loading and inferencing within try/except blocks, and if we get a failure, we write the error messages into the output file. 

We use logger from lmstrix.utils.logging

