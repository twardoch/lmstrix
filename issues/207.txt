WHen I do:


```
Othello:~ adam$ lmstrix list --sort dtx
```

I get: 

```
                                                     LM Studio Models
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━┓
┃                                          ┃ Size     ┃ Declared   ┃ Tested     ┃ Last       ┃ Last       ┃              ┃
┃ Model ID                                 ┃ (GB)     ┃ Ctx        ┃ Ctx        ┃ Good       ┃ Bad        ┃ Status       ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━┩
│ text-embedding-nomic-embed-text-v2       │ 0.48     │ 2,048      │ -          │ -          │ -          │ Untested     │
│ text-embedding-nomic-embed-text-v1.5     │ 0.08     │ 2,048      │ -          │ -          │ -          │ Untested     │
│ comedy_13b_dpo                           │ 9.95     │ 4,096      │ 4,096      │ 4,096      │ -          │ ✓ Tested     │
│ text-embedding-mxbai-embed-xsmall-v1-i1  │ 0.03     │ 4,096      │ -          │ -          │ -          │ Untested     │
│ j.a.r.v.i.s-v2.0                         │ 7.95     │ 8,192      │ 8,192      │ 8,192      │ -          │ ✓ Tested     │
│ meta-llama-3-8b-instruct                 │ 7.95     │ 8,192      │ 8,192      │ 8,192      │ -          │ ✓ Tested     │
│ text-embedding-qwen3-embedding-0.6b      │ 0.26     │ 32,768     │ -          │ -          │ -          │ Untested     │
│ qwensummarizer3.0                        │ 3.06     │ 32,768     │ 32,768     │ 32,768     │ -          │ ✓ Tested     │
│ mistral-small-24b-instruct-2501-writer-… │ 9.69     │ 32,768     │ 32,768     │ 32,768     │ -          │ ✓ Tested     │
│ comicbot_v.2                             │ 5.53     │ 32,768     │ 32,768     │ 32,768     │ -          │ ✓ Tested     │
│ mistral-7b-sarcasm-scrolls-v2            │ 7.17     │ 32,768     │ 32,768     │ 32,768     │ -          │ ✓ Tested     │
│ mlabonne_qwen3-14b-abliterated           │ 10.24    │ 40,960     │ 40,960     │ 40,960     │ -          │ ✓ Tested     │
│ smoothie-qwen3-14b-i1                    │ 9.79     │ 40,960     │ 40,960     │ 40,960     │ -          │ ✓ Tested     │
│ llama-3-8b-instruct-64k                  │ 7.95     │ 64,000     │ 2,048      │ 2,048      │ 64,000     │ ✓ Tested     │
│ llama-3-soliloquy-8b-v1.5-64k-i          │ 6.14     │ 65,536     │ 2,048      │ 2,048      │ 65,536     │ ✓ Tested     │
│ smollm3-3b@q4_k_m                        │ 1.78     │ 65,536     │ 65,536     │ 65,536     │ -          │ ✓ Tested     │
│ smollm3-3b@q8_0                          │ 3.05     │ 65,536     │ 65,536     │ 65,536     │ -          │ ✓ Tested     │
│ meta-llama-3-8b-instruct-64k             │ 7.95     │ 65,536     │ 2,048      │ 2,048      │ 65,536     │ ✓ Tested     │
│ jina-embeddings-v4-text-retrieval@q3_k_m │ 1.48     │ 128,000    │ -          │ -          │ -          │ Untested     │
│ jina-embeddings-v4-text-retrieval@q8_0   │ 3.06     │ 128,000    │ -          │ -          │ -          │ Untested     │
│ qwen/qwen2.5-vl-7b                       │ 8.80     │ 128,000    │ 102,400    │ 102,400    │ -          │ Testing...   │
│ prithivmlmods.llama-chat-summary-3.2-3b  │ 3.19     │ 131,072    │ 102,400    │ 102,400    │ -          │ Testing...   │
│ lucy-128k                                │ 1.71     │ 131,072    │ 102,400    │ 102,400    │ -          │ Testing...   │
│ dream-org_dream-v0-instruct-7b           │ 2.59     │ 131,072    │ 102,400    │ 102,400    │ -          │ Testing...   │
│ llama-3.2-3b-instruct                    │ 1.80     │ 131,072    │ 2,048      │ 2,048      │ 102,400    │ ✓ Tested     │
│ deepseek-r1-distill-qwen-14b             │ 8.37     │ 131,072    │ 2,048      │ 2,048      │ -          │ Testing...   │
│ llama-3.1-8b-sarcasm@q3_k_l              │ 4.03     │ 131,072    │ 2,048      │ 2,048      │ -          │ Testing...   │
│ llama-3.1-8b-sarcasm@q4_k_s              │ 4.37     │ 131,072    │ 2,048      │ 2,048      │ -          │ Testing...   │
│ llama-3.1-8b-sarcasm@q5_k_s              │ 5.21     │ 131,072    │ 2,048      │ 2,048      │ -          │ Testing...   │
│ llama-3.1-8b-sarcasm@q6_k                │ 6.14     │ 131,072    │ 2,048      │ 2,048      │ -          │ Testing...   │
│ llama-3.1-8b-sarcasm@q8_0                │ 7.95     │ 131,072    │ 2,048      │ 2,048      │ -          │ Testing...   │
│ qwen2.5-microsoft-nextcoder-brainstorm2… │ 7.79     │ 131,072    │ 2,048      │ 2,048      │ -          │ Testing...   │
│ rei-24b-kto                              │ 10.69    │ 131,072    │ 2,048      │ 2,048      │ -          │ Testing...   │
│ sarcasmll-1b                             │ 1.23     │ 131,072    │ 2,048      │ 2,048      │ -          │ Testing...   │
│ ultron-summarizer-1b                     │ 0.60     │ 131,072    │ 2,048      │ 2,048      │ -          │ Testing...   │
│ ultron-summarizer-8b                     │ 7.95     │ 131,072    │ 2,048      │ 2,048      │ -          │ Testing...   │
│ nazareai-senior-marketing-strategist     │ 3.19     │ 131,072    │ 2,048      │ 2,048      │ -          │ Testing...   │
│ qwen3-14b-128k                           │ 9.82     │ 131,072    │ 2,048      │ 2,048      │ -          │ Testing...   │
│ qwen3-8b-128k                            │ 6.98     │ 131,072    │ 2,048      │ 2,048      │ -          │ Testing...   │
│ smollm3-3b-128k                          │ 0.89     │ 131,072    │ 2,048      │ 2,048      │ -          │ Testing...   │
│ summllama3.1-8b                          │ 7.95     │ 131,072    │ 2,048      │ 2,048      │ -          │ Testing...   │
│ qwen3-8b-256k-context-8x-grand@q3_k_m    │ 3.84     │ 262,144    │ 2,048      │ 2,048      │ -          │ Testing...   │
│ qwen3-8b-256k-context-8x-grand@q4_k_m    │ 4.68     │ 262,144    │ 2,048      │ 2,048      │ -          │ Testing...   │
│ qwen3-8b-256k-context-8x-grand@q5_k_m    │ 5.45     │ 262,144    │ 2,048      │ 2,048      │ -          │ Testing...   │
│ qwen3-8b-256k-context-8x-grand-i1@iq1_s  │ 1.97     │ 262,144    │ 2,048      │ 2,048      │ -          │ Testing...   │
│ qwen3-8b-256k-context-8x-grand-i1@iq2_m  │ 2.84     │ 262,144    │ 2,048      │ 2,048      │ -          │ Testing...   │
│ qwen3-8b-256k-context-8x-grand-i1@iq4_xs │ 4.25     │ 262,144    │ 2,048      │ 2,048      │ -          │ Testing...   │
│ qwen3-8b-256k-context-8x-grand-i1@q6_k   │ 6.26     │ 262,144    │ 2,048      │ 2,048      │ -          │ Testing...   │
│ qwen3-8b-320k-context-10x-massive        │ 8.11     │ 327,680    │ 2,048      │ 2,048      │ -          │ Testing...   │
│ princeton-nlp.llama-3-8b-prolong-512k-i… │ 7.95     │ 524,288    │ 2,048      │ 2,048      │ -          │ Testing...   │
│ megabeam-mistral-7b-512k                 │ 7.17     │ 524,288    │ 2,048      │ 2,048      │ -          │ Testing...   │
│ ward-12b-model_stock-i1                  │ 7.93     │ 1,024,000  │ 2,048      │ 2,048      │ -          │ Testing...   │
│ llama3-8b-darkidol-2.1-uncensored-1048k… │ 3.05     │ 1,048,576  │ 2,048      │ 2,048      │ -          │ Testing...   │
│ llama-3-8b-instruct-gradient-1048k       │ 3.41     │ 1,048,576  │ 2,048      │ 2,048      │ -          │ Testing...   │
│ wemake-llama-3-8b-instruct-v41-1048k     │ 7.95     │ 1,048,576  │ 2,048      │ 2,048      │ -          │ Testing...   │
│ granite-4.0-tiny-preview                 │ 6.62     │ 1,048,576  │ 2,048      │ 2,048      │ -          │ Testing...   │
│ llama-3.1-1-million-ctx-deephermes-deep… │ 3.41     │ 1,073,152  │ 2,048      │ 2,048      │ -          │ Testing...   │
└──────────────────────────────────────────┴──────────┴────────────┴────────────┴────────────┴────────────┴──────────────┘
Othello:~ adam$
```

Double-check and analyze the code and make sure that: 

- When we do "test", the tool MUST write a simple log of ATTEMPTS and SOLUTIONS for each context size and model. The log should be written as simple lines in the LMStudio folder as `lmstrix.log.txt`
- When we do "test", the tool must RESUME the testing (skip the combinations that have actually been tested)
